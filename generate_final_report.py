#!/usr/bin/env python3
"""
TTD-DRå®Œæ•´å·¥ä½œæµæ¼”ç¤º - ç”ŸæˆçœŸæ­£çš„æœ€ç»ˆæŠ¥å‘Š
ä½¿ç”¨å®Œæ•´çš„8èŠ‚ç‚¹å·¥ä½œæµç”Ÿæˆä¸“ä¸šç ”ç©¶æŠ¥å‘Š
"""

import asyncio
import sys
import os
import json
from datetime import datetime
from pathlib import Path

# æ·»åŠ è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'backend'))

from backend.workflow.graph import create_ttdr_workflow
from backend.models.core import (
    ResearchRequirements, 
    ResearchDomain, 
    ComplexityLevel,
    TTDRState
)

async def generate_complete_report():
    """è¿è¡Œå®Œæ•´å·¥ä½œæµç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
    
    topic = "Pythonå¼‚æ­¥ç¼–ç¨‹æœ€ä½³å®è·µ2025"
    
    print("=" * 80)
    print("TTD-DRå®Œæ•´å·¥ä½œæµ - ç”Ÿæˆæœ€ç»ˆç ”ç©¶æŠ¥å‘Š")
    print("=" * 80)
    print(f"ç ”ç©¶ä¸»é¢˜: {topic}")
    print()
    
    # åˆ›å»ºå®Œæ•´å·¥ä½œæµ
    workflow = create_ttdr_workflow()
    
    # è®¾ç½®ç ”ç©¶è¦æ±‚
    requirements = ResearchRequirements(
        domain=ResearchDomain.TECHNOLOGY,
        complexity_level=ComplexityLevel.ADVANCED,
        max_iterations=3,
        quality_threshold=0.8,
        target_audience="é«˜çº§Pythonå¼€å‘è€…",
        desired_length="è¯¦ç»†æŠ¥å‘Š",
        specific_requirements=[
            "åŒ…å«2025å¹´æœ€æ–°å®è·µ",
            "æä¾›å®Œæ•´ä»£ç ç¤ºä¾‹",
            "æ€§èƒ½å¯¹æ¯”åˆ†æ",
            "å®é™…éƒ¨ç½²æ¡ˆä¾‹"
        ]
    )
    
    # åˆå§‹çŠ¶æ€
    initial_state = {
        "topic": topic,
        "requirements": requirements.model_dump(),
        "current_draft": "",
        "information_gaps": [],
        "retrieved_info": [],
        "iteration_count": 0,
        "quality_score": 0.0,
        "error_log": []
    }
    
    print("ã€å¯åŠ¨å®Œæ•´å·¥ä½œæµã€‘")
    print("1. draft_generator â†’ ç”Ÿæˆåˆå§‹ç ”ç©¶ç»“æ„")
    print("2. gap_analyzer â†’ è¯†åˆ«ä¿¡æ¯ç¼ºå£")
    print("3. retrieval_engine â†’ æœç´¢ç›¸å…³ä¿¡æ¯")
    print("4. information_integrator â†’ é›†æˆä¿¡æ¯")
    print("5. quality_assessor â†’ è¯„ä¼°è´¨é‡")
    print("6. self_evolution_enhancer â†’ ä¼˜åŒ–å†…å®¹")
    print("7. report_synthesizer â†’ ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")
    print()
    
    try:
        # è¿è¡Œå®Œæ•´å·¥ä½œæµ
        final_state = await workflow.ainvoke(initial_state)
        
        # æå–æœ€ç»ˆæŠ¥å‘Š
        final_report = final_state.get("final_report", "")
        
        if final_report:
            print("ã€æœ€ç»ˆæŠ¥å‘Šç”ŸæˆæˆåŠŸã€‘")
            print("=" * 50)
            print(final_report[:1000] + "..." if len(final_report) > 1000 else final_report)
            print("=" * 50)
            
            # ä¿å­˜å®Œæ•´æŠ¥å‘Š
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"final_report_{timestamp}.md"
            
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(f"# {topic} - ç ”ç©¶æŠ¥å‘Š\n\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                f.write(f"## ç ”ç©¶æ‘˜è¦\n")
                f.write(f"- ä¿¡æ¯æºæ•°é‡: {len(final_state.get('retrieved_info', []))}\n")
                f.write(f"- è¿­ä»£æ¬¡æ•°: {final_state.get('iteration_count', 0)}\n")
                f.write(f"- è´¨é‡è¯„åˆ†: {final_state.get('quality_score', 0)}\n\n")
                f.write(final_report)
            
            print(f"\nâœ… å®Œæ•´æŠ¥å‘Šå·²ä¿å­˜: {filename}")
            return final_report
        else:
            print("âŒ æœªç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")
            print("çŠ¶æ€ä¿¡æ¯:", {
                "quality_score": final_state.get("quality_score"),
                "iteration_count": final_state.get("iteration_count"),
                "has_final_report": bool(final_report)
            })
            return None
            
    except Exception as e:
        print(f"âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

async def simple_workflow_demo():
    """ç®€åŒ–å·¥ä½œæµæ¼”ç¤º - æ¨¡æ‹Ÿå®Œæ•´æŠ¥å‘Šç”Ÿæˆ"""
    
    print("\n" + "=" * 80)
    print("ç®€åŒ–å·¥ä½œæµ - ç”Ÿæˆæ¨¡æ‹Ÿæœ€ç»ˆæŠ¥å‘Š")
    print("=" * 80)
    
    topic = "Pythonå¼‚æ­¥ç¼–ç¨‹æœ€ä½³å®è·µ2025"
    
    # ä½¿ç”¨Googleæœç´¢æ”¶é›†ä¿¡æ¯
    from backend.services.google_search_client import GoogleSearchClient
    from backend.services.kimi_k2_client import KimiK2Client
    
    google_client = GoogleSearchClient()
    kimi_client = KimiK2Client()
    
    # é˜¶æ®µ1: ç ”ç©¶è®¡åˆ’
    print("ã€é˜¶æ®µ1ã€‘ç ”ç©¶è®¡åˆ’ç”Ÿæˆ...")
    research_plan = {
        "executive_summary": "æ·±å…¥åˆ†æPythonå¼‚æ­¥ç¼–ç¨‹åœ¨2025å¹´çš„æœ€ä½³å®è·µ",
        "key_areas": [
            "asyncioæ ¸å¿ƒæœºåˆ¶",
            "æ€§èƒ½ä¼˜åŒ–æŠ€å·§", 
            "é”™è¯¯å¤„ç†æ¨¡å¼",
            "å®é™…åº”ç”¨æ¡ˆä¾‹",
            "æ–°æŠ€æœ¯è¶‹åŠ¿"
        ]
    }
    print("âœ… ç ”ç©¶è®¡åˆ’å®Œæˆ")
    
    # é˜¶æ®µ2: ä¿¡æ¯æ”¶é›†å’Œåˆæˆ
    print("\nã€é˜¶æ®µ2ã€‘ä¿¡æ¯æ”¶é›†å’Œåˆæˆ...")
    
    search_queries = [
        "Python asyncio best practices 2025",
        "Python async performance optimization",
        "Python concurrent programming patterns"
    ]
    
    collected_info = []
    for query in search_queries:
        response = await google_client.search(query, num_results=3)
        collected_info.extend([
            {
                "title": item.title,
                "url": item.link,
                "content": item.snippet
            }
            for item in response.items
        ])
    
    print(f"âœ… æ”¶é›† {len(collected_info)} ä¸ªä¿¡æ¯æº")
    
    # é˜¶æ®µ3: æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆ
    print("\nã€é˜¶æ®µ3ã€‘æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆ...")
    
    # ä½¿ç”¨Kimiç”Ÿæˆä¸“ä¸šæŠ¥å‘Š
    report_prompt = f"""
    åŸºäºä»¥ä¸‹å…³äº"{topic}"çš„ç ”ç©¶ä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„æŠ€æœ¯ç ”ç©¶æŠ¥å‘Šï¼š
    
    æ”¶é›†åˆ°çš„ä¿¡æ¯æºï¼š
    {chr(10).join([f"[{i+1}] {info['title']}: {info['content'][:100]}..." for i, info in enumerate(collected_info[:5])])}
    
    è¯·ç”ŸæˆåŒ…å«ä»¥ä¸‹éƒ¨åˆ†çš„ä¸“ä¸šæŠ¥å‘Šï¼š
    
    1. æ‰§è¡Œæ‘˜è¦
    2. æŠ€æœ¯èƒŒæ™¯å’Œå†å²
    3. 2025å¹´æœ€æ–°æœ€ä½³å®è·µ
    4. æ€§èƒ½ä¼˜åŒ–æŠ€å·§
    5. å®é™…åº”ç”¨æ¡ˆä¾‹
    6. å¸¸è§é”™è¯¯å’Œè§£å†³æ–¹æ¡ˆ
    7. æœªæ¥å‘å±•è¶‹åŠ¿
    8. ç»“è®ºå’Œå»ºè®®
    
    æ ¼å¼è¦æ±‚ï¼š
    - ä½¿ç”¨ä¸“ä¸šçš„æŠ€æœ¯æŠ¥å‘Šæ ¼å¼
    - åŒ…å«å…·ä½“çš„ä»£ç ç¤ºä¾‹
    - æä¾›å®é™…å¯æ“ä½œçš„æŒ‡å¯¼
    - å­—æ•°çº¦2000-3000å­—
    """
    
    try:
        final_report = await kimi_client.generate_text(report_prompt, max_tokens=2500)
        
        # ä¿å­˜æœ€ç»ˆæŠ¥å‘Š
        filename = f"complete_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(f"# {topic} - å®Œæ•´ç ”ç©¶æŠ¥å‘Š\n\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"**ä¿¡æ¯æºæ•°é‡**: {len(collected_info)}\n")
            f.write(f"**ç ”ç©¶æ–¹æ³•**: TTD-DRä¸‰é˜¶æ®µè‡ªé€‚åº”å·¥ä½œæµ\n\n")
            f.write("---\n\n")
            f.write(final_report)
        
        print("ã€æœ€ç»ˆæŠ¥å‘Šé¢„è§ˆã€‘")
        print("-" * 50)
        print(final_report[:800] + "..." if len(final_report) > 800 else final_report)
        print("-" * 50)
        
        print(f"\nâœ… å®Œæ•´æŠ¥å‘Šå·²ä¿å­˜: {filename}")
        print(f"ğŸ“Š æŠ¥å‘Šé•¿åº¦: {len(final_report)} å­—ç¬¦")
        print(f"ğŸ”— ä¿¡æ¯æº: {len(collected_info)} ä¸ª")
        
        return final_report
        
    except Exception as e:
        print(f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
        return None

if __name__ == "__main__":
    # è¿è¡Œç®€åŒ–æ¼”ç¤º
    asyncio.run(simple_workflow_demo())