"""
ä½¿ç”¨Kimi K2æ¨¡å‹ç”Ÿæˆå®Œæ•´ç ”ç©¶æŠ¥å‘Š
Complete research report generation using Kimi K2 model
"""

import asyncio
import logging
import json
import time
from datetime import datetime
from pathlib import Path
import sys

# Add backend to path
sys.path.insert(0, str(Path(__file__).parent / "backend"))

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

async def generate_research_report_with_kimi_k2(topic: str, complexity: str = "intermediate"):
    """
    ä½¿ç”¨Kimi K2æ¨¡å‹ç”Ÿæˆå®Œæ•´çš„ç ”ç©¶æŠ¥å‘Š
    
    Args:
        topic: ç ”ç©¶ä¸»é¢˜
        complexity: å¤æ‚åº¦çº§åˆ«
    """
    logger.info(f"å¼€å§‹ä½¿ç”¨Kimi K2ç”Ÿæˆç ”ç©¶æŠ¥å‘Š: {topic}")
    
    try:
        # Import Kimi K2 client
        from services.kimi_k2_client import KimiK2Client
        from config.settings import settings
        
        # Verify Kimi K2 configuration
        logger.info(f"ä½¿ç”¨æ¨¡å‹: {settings.kimi_k2_model}")
        logger.info(f"APIç«¯ç‚¹: {settings.kimi_k2_base_url}")
        
        # Generate execution ID
        execution_id = f"kimi_k2_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{topic.replace(' ', '_')[:20]}"
        start_time = time.time()
        
        async with KimiK2Client() as client:
            logger.info("Kimi K2å®¢æˆ·ç«¯è¿æ¥æˆåŠŸ")
            
            # Step 1: ç”Ÿæˆç ”ç©¶å¤§çº²
            logger.info("æ­¥éª¤1: ç”Ÿæˆç ”ç©¶å¤§çº²...")
            outline_prompt = f"""
è¯·ä¸ºä¸»é¢˜"{topic}"ç”Ÿæˆä¸€ä¸ªè¯¦ç»†çš„ç ”ç©¶æŠ¥å‘Šå¤§çº²ã€‚

è¦æ±‚:
1. åŒ…å«å®Œæ•´çš„ç« èŠ‚ç»“æ„
2. æ¯ä¸ªç« èŠ‚éƒ½æœ‰å…·ä½“çš„å­ä¸»é¢˜
3. é€‚åˆ{complexity}çº§åˆ«çš„æ·±åº¦åˆ†æ
4. ç¬¦åˆå­¦æœ¯ç ”ç©¶æŠ¥å‘Šçš„æ ‡å‡†æ ¼å¼
5. åŒ…å«å¼•è¨€ã€ç°çŠ¶åˆ†æã€å‘å±•è¶‹åŠ¿ã€æŒ‘æˆ˜ä¸æœºé‡ã€æ¡ˆä¾‹ç ”ç©¶ã€æ”¿ç­–å»ºè®®ã€ç»“è®ºç­‰éƒ¨åˆ†

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œå¹¶æä¾›è¯¦ç»†çš„å¤§çº²ç»“æ„ã€‚
"""
            
            outline_response = await client.generate_text(outline_prompt, max_tokens=1000)
            logger.info(f"å¤§çº²ç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(outline_response.content)} å­—ç¬¦")
            
            # Step 2: ç”Ÿæˆè¯¦ç»†å†…å®¹
            logger.info("æ­¥éª¤2: ç”Ÿæˆè¯¦ç»†ç ”ç©¶å†…å®¹...")
            content_prompt = f"""
åŸºäºä»¥ä¸‹å¤§çº²ï¼Œè¯·ä¸ºä¸»é¢˜"{topic}"æ’°å†™ä¸€ä»½å®Œæ•´çš„ç ”ç©¶æŠ¥å‘Šã€‚

å¤§çº²:
{outline_response.content}

è¦æ±‚:
1. æ¯ä¸ªç« èŠ‚éƒ½è¦æœ‰è¯¦ç»†çš„å†…å®¹ï¼Œä¸å°‘äº200å­—
2. åŒ…å«å…·ä½“çš„æ•°æ®ã€æ¡ˆä¾‹å’Œåˆ†æ
3. è¯­è¨€ä¸“ä¸šã€é€»è¾‘æ¸…æ™°
4. é€‚åˆ{complexity}çº§åˆ«çš„ä¸“ä¸šæ·±åº¦
5. åŒ…å«å…·ä½“çš„å®ä¾‹å’Œåº”ç”¨åœºæ™¯
6. æä¾›å®ç”¨çš„å»ºè®®å’Œå±•æœ›
7. æ€»å­—æ•°æ§åˆ¶åœ¨3000-5000å­—ä¹‹é—´

è¯·ç”Ÿæˆå®Œæ•´çš„ç ”ç©¶æŠ¥å‘Šå†…å®¹ï¼Œä½¿ç”¨æ ‡å‡†çš„Markdownæ ¼å¼ã€‚
"""
            
            content_response = await client.generate_text(content_prompt, max_tokens=3000)
            logger.info(f"è¯¦ç»†å†…å®¹ç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(content_response.content)} å­—ç¬¦")
            
            # Step 3: è´¨é‡è¯„ä¼°å’Œä¼˜åŒ–
            logger.info("æ­¥éª¤3: è´¨é‡è¯„ä¼°å’Œå†…å®¹ä¼˜åŒ–...")
            quality_prompt = f"""
è¯·è¯„ä¼°ä»¥ä¸‹ç ”ç©¶æŠ¥å‘Šçš„è´¨é‡ï¼Œå¹¶æä¾›æ”¹è¿›å»ºè®®:

æŠ¥å‘Šå†…å®¹:
{content_response.content[:2000]}...

è¯„ä¼°ç»´åº¦:
1. å†…å®¹å®Œæ•´æ€§ (0-1åˆ†)
2. é€»è¾‘è¿è´¯æ€§ (0-1åˆ†)  
3. ä¸“ä¸šå‡†ç¡®æ€§ (0-1åˆ†)
4. å®ç”¨ä»·å€¼ (0-1åˆ†)
5. è¯­è¨€è¡¨è¾¾ (0-1åˆ†)

è¯·æä¾›JSONæ ¼å¼çš„è¯„ä¼°ç»“æœ:
{{
    "completeness": 0.0-1.0,
    "coherence": 0.0-1.0,
    "accuracy": 0.0-1.0,
    "practicality": 0.0-1.0,
    "expression": 0.0-1.0,
    "overall_score": 0.0-1.0,
    "suggestions": ["æ”¹è¿›å»ºè®®1", "æ”¹è¿›å»ºè®®2"]
}}
"""
            
            quality_schema = {
                "type": "object",
                "properties": {
                    "completeness": {"type": "number"},
                    "coherence": {"type": "number"},
                    "accuracy": {"type": "number"},
                    "practicality": {"type": "number"},
                    "expression": {"type": "number"},
                    "overall_score": {"type": "number"},
                    "suggestions": {"type": "array", "items": {"type": "string"}}
                }
            }
            
            quality_assessment = await client.generate_structured_response(
                quality_prompt, quality_schema, max_tokens=500
            )
            logger.info(f"è´¨é‡è¯„ä¼°å®Œæˆï¼Œæ€»åˆ†: {quality_assessment.get('overall_score', 0):.3f}")
            
            # Step 4: æ ¹æ®è¯„ä¼°ç»“æœä¼˜åŒ–å†…å®¹
            if quality_assessment.get('overall_score', 0) < 0.8:
                logger.info("æ­¥éª¤4: æ ¹æ®è¯„ä¼°ç»“æœä¼˜åŒ–å†…å®¹...")
                optimization_prompt = f"""
è¯·æ ¹æ®ä»¥ä¸‹è¯„ä¼°å»ºè®®ä¼˜åŒ–ç ”ç©¶æŠ¥å‘Š:

åŸå§‹æŠ¥å‘Š:
{content_response.content}

æ”¹è¿›å»ºè®®:
{', '.join(quality_assessment.get('suggestions', []))}

è¯·ç”Ÿæˆä¼˜åŒ–åçš„å®Œæ•´æŠ¥å‘Šï¼Œé‡ç‚¹æ”¹è¿›ä»¥ä¸‹æ–¹é¢:
1. æé«˜å†…å®¹çš„å®Œæ•´æ€§å’Œæ·±åº¦
2. å¢å¼ºé€»è¾‘è¿è´¯æ€§
3. è¡¥å……æ›´å¤šä¸“ä¸šæ•°æ®å’Œæ¡ˆä¾‹
4. æå‡å®ç”¨ä»·å€¼
5. ä¼˜åŒ–è¯­è¨€è¡¨è¾¾

ä¿æŒMarkdownæ ¼å¼ï¼Œç¡®ä¿æŠ¥å‘Šçš„ä¸“ä¸šæ€§å’Œå¯è¯»æ€§ã€‚
"""
                
                optimized_response = await client.generate_text(optimization_prompt, max_tokens=3500)
                final_content = optimized_response.content
                logger.info("å†…å®¹ä¼˜åŒ–å®Œæˆ")
            else:
                final_content = content_response.content
                logger.info("å†…å®¹è´¨é‡è‰¯å¥½ï¼Œæ— éœ€ä¼˜åŒ–")
            
            # Calculate execution time
            execution_time = time.time() - start_time
            
            # Create final report with metadata
            final_report = f"""# ç ”ç©¶æŠ¥å‘Š: {topic}

**ç”±TTD-DRæ¡†æ¶ç”Ÿæˆ (ä½¿ç”¨Kimi K2æ¨¡å‹)**
**æ‰§è¡ŒID:** {execution_id}
**ç”Ÿæˆæ—¶é—´:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**æ‰§è¡Œæ—¶é—´:** {execution_time:.2f} ç§’
**ä½¿ç”¨æ¨¡å‹:** {settings.kimi_k2_model}
**å¤æ‚åº¦çº§åˆ«:** {complexity}
**è´¨é‡è¯„åˆ†:** {quality_assessment.get('overall_score', 0):.3f}

---

{final_content}

---

## è´¨é‡è¯„ä¼°è¯¦æƒ…

- **å†…å®¹å®Œæ•´æ€§:** {quality_assessment.get('completeness', 0):.3f}
- **é€»è¾‘è¿è´¯æ€§:** {quality_assessment.get('coherence', 0):.3f}
- **ä¸“ä¸šå‡†ç¡®æ€§:** {quality_assessment.get('accuracy', 0):.3f}
- **å®ç”¨ä»·å€¼:** {quality_assessment.get('practicality', 0):.3f}
- **è¯­è¨€è¡¨è¾¾:** {quality_assessment.get('expression', 0):.3f}
- **æ€»ä½“è¯„åˆ†:** {quality_assessment.get('overall_score', 0):.3f}

## æ”¹è¿›å»ºè®®

{chr(10).join(f"- {suggestion}" for suggestion in quality_assessment.get('suggestions', []))}

---
*æœ¬æŠ¥å‘Šç”±TTD-DRæ¡†æ¶ä½¿ç”¨Kimi K2æ¨¡å‹ ({settings.kimi_k2_model}) ç”Ÿæˆ*
"""
            
            # Save report to file
            safe_topic = "".join(c for c in topic if c.isalnum() or c in (' ', '-', '_')).strip()
            safe_topic = safe_topic.replace(' ', '_')[:50]
            report_filename = f"kimi_k2_report_{execution_id}_{safe_topic}.md"
            
            with open(report_filename, 'w', encoding='utf-8') as f:
                f.write(final_report)
            
            logger.info(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_filename}")
            
            # Return results
            return {
                "success": True,
                "execution_id": execution_id,
                "execution_time": execution_time,
                "report_file": report_filename,
                "quality_score": quality_assessment.get('overall_score', 0),
                "report_length": len(final_content),
                "model_used": settings.kimi_k2_model,
                "steps_completed": 4 if quality_assessment.get('overall_score', 0) < 0.8 else 3
            }
            
    except Exception as e:
        logger.error(f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {
            "success": False,
            "error": str(e),
            "execution_time": time.time() - start_time if 'start_time' in locals() else 0
        }

async def main():
    """è¿è¡Œä¸¤ä¸ªç ”ç©¶æŠ¥å‘Šç”Ÿæˆä»»åŠ¡"""
    print("ğŸš€ ä½¿ç”¨Kimi K2æ¨¡å‹ç”Ÿæˆç ”ç©¶æŠ¥å‘Š")
    print("=" * 80)
    
    # å®šä¹‰ä¸¤ä¸ªç ”ç©¶ä¸»é¢˜
    topics = [
        {
            "topic": "äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—è¯Šæ–­ä¸­çš„åº”ç”¨ç°çŠ¶ä¸å‘å±•å‰æ™¯",
            "complexity": "advanced",
            "description": "AIåœ¨åŒ»ç–—è¯Šæ–­é¢†åŸŸçš„æ·±åº¦åº”ç”¨åˆ†æ"
        },
        {
            "topic": "5GæŠ€æœ¯å¯¹æ™ºæ…§åŸå¸‚å»ºè®¾çš„æ¨åŠ¨ä½œç”¨ç ”ç©¶",
            "complexity": "intermediate", 
            "description": "5GæŠ€æœ¯åœ¨æ™ºæ…§åŸå¸‚ä¸­çš„åº”ç”¨å’Œå½±å“"
        }
    ]
    
    results = []
    total_start_time = time.time()
    
    for i, topic_config in enumerate(topics, 1):
        print(f"\nğŸ“Š æŠ¥å‘Š {i}/2: {topic_config['topic']}")
        print(f"æè¿°: {topic_config['description']}")
        print(f"å¤æ‚åº¦: {topic_config['complexity']}")
        print("-" * 60)
        
        result = await generate_research_report_with_kimi_k2(
            topic=topic_config["topic"],
            complexity=topic_config["complexity"]
        )
        
        results.append({
            "topic": topic_config["topic"],
            "description": topic_config["description"],
            "result": result
        })
        
        if result["success"]:
            print(f"âœ… æŠ¥å‘Š {i} ç”ŸæˆæˆåŠŸ!")
            print(f"   æ‰§è¡Œæ—¶é—´: {result['execution_time']:.2f}ç§’")
            print(f"   è´¨é‡è¯„åˆ†: {result['quality_score']:.3f}")
            print(f"   ä½¿ç”¨æ¨¡å‹: {result['model_used']}")
            print(f"   å¤„ç†æ­¥éª¤: {result['steps_completed']}")
            print(f"   æ–‡ä»¶: {result['report_file']}")
        else:
            print(f"âŒ æŠ¥å‘Š {i} ç”Ÿæˆå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        # çŸ­æš‚æš‚åœé¿å…APIé™åˆ¶
        if i < len(topics):
            print("â³ å‡†å¤‡ä¸‹ä¸€ä¸ªæŠ¥å‘Š...")
            await asyncio.sleep(2)
    
    total_execution_time = time.time() - total_start_time
    
    # æœ€ç»ˆæ€»ç»“
    print("\n" + "=" * 80)
    print("ğŸ‰ Kimi K2ç ”ç©¶æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
    print("=" * 80)
    
    successful_reports = sum(1 for r in results if r["result"]["success"])
    failed_reports = len(results) - successful_reports
    
    print(f"æ€»æŠ¥å‘Šæ•°é‡: {len(results)}")
    print(f"æˆåŠŸæŠ¥å‘Š: {successful_reports}")
    print(f"å¤±è´¥æŠ¥å‘Š: {failed_reports}")
    print(f"æ€»æ‰§è¡Œæ—¶é—´: {total_execution_time:.2f} ç§’")
    
    if successful_reports > 0:
        avg_quality = sum(r["result"]["quality_score"] for r in results if r["result"]["success"]) / successful_reports
        print(f"å¹³å‡è´¨é‡è¯„åˆ†: {avg_quality:.3f}")
    
    print("\næŠ¥å‘Šè¯¦æƒ…:")
    print("-" * 40)
    
    for i, result_data in enumerate(results, 1):
        result = result_data["result"]
        print(f"\næŠ¥å‘Š {i}: {result_data['topic']}")
        print(f"æè¿°: {result_data['description']}")
        
        if result["success"]:
            print(f"âœ… çŠ¶æ€: æˆåŠŸ")
            print(f"   æ‰§è¡Œæ—¶é—´: {result['execution_time']:.2f}ç§’")
            print(f"   è´¨é‡è¯„åˆ†: {result['quality_score']:.3f}")
            print(f"   æŠ¥å‘Šé•¿åº¦: {result['report_length']:,} å­—ç¬¦")
            print(f"   ä½¿ç”¨æ¨¡å‹: {result['model_used']}")
            print(f"   æ–‡ä»¶: {result['report_file']}")
        else:
            print(f"âŒ çŠ¶æ€: å¤±è´¥")
            print(f"   é”™è¯¯: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            print(f"   æ‰§è¡Œæ—¶é—´: {result.get('execution_time', 0):.2f}ç§’")
    
    print(f"\nğŸ¯ ä½¿ç”¨Kimi K2æ¨¡å‹ç”Ÿæˆå®Œæˆ! è¯·æŸ¥çœ‹ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶ã€‚")
    
    return results

if __name__ == "__main__":
    # è¿è¡Œå®Œæ•´æ¼”ç¤º
    results = asyncio.run(main())
    
    # æ ¹æ®ç»“æœé€€å‡º
    successful = sum(1 for r in results if r["result"]["success"])
    exit(0 if successful > 0 else 1)