"""
Complete TTD-DR Framework Demo
Run two comprehensive research reports to demonstrate the full system capabilities
"""

import asyncio
import logging
import json
import time
from datetime import datetime
from pathlib import Path

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Add current directory to path
import sys
sys.path.insert(0, str(Path(__file__).parent))

async def run_complete_research_report(topic: str, complexity: str = "intermediate", max_iterations: int = 3):
    """
    Run a complete research report using the TTD-DR framework
    
    Args:
        topic: Research topic
        complexity: Complexity level (basic, intermediate, advanced, expert)
        max_iterations: Maximum number of iterations
    """
    logger.info(f"Starting complete research report for: {topic}")
    
    try:
        # Import required components
        from backend.models.core import ResearchRequirements, ResearchDomain, ComplexityLevel
        from backend.workflow.workflow_orchestrator import WorkflowExecutionEngine, create_workflow_state
        from backend.services.monitoring_alerting import global_monitoring_system
        
        # Create research requirements
        complexity_map = {
            "basic": ComplexityLevel.BASIC,
            "intermediate": ComplexityLevel.INTERMEDIATE,
            "advanced": ComplexityLevel.ADVANCED,
            "expert": ComplexityLevel.EXPERT
        }
        
        requirements = ResearchRequirements(
            domain=ResearchDomain.TECHNOLOGY,  # Default to technology
            complexity_level=complexity_map.get(complexity, ComplexityLevel.INTERMEDIATE),
            max_iterations=max_iterations,
            quality_threshold=0.8,
            max_sources=10,
            preferred_source_types=["academic", "news", "technical"]
        )
        
        # Create initial workflow state
        initial_state = create_workflow_state(topic, requirements)
        
        # Generate execution ID
        execution_id = f"demo_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{topic.replace(' ', '_')[:20]}"
        
        # Start monitoring system
        if not global_monitoring_system.monitoring_active:
            await global_monitoring_system.start_monitoring()
            logger.info("Monitoring system started")
        
        # Create workflow engine
        workflow_engine = WorkflowExecutionEngine()
        
        # Record start time
        start_time = time.time()
        
        logger.info(f"Executing workflow for: {topic}")
        logger.info(f"Execution ID: {execution_id}")
        logger.info(f"Complexity: {complexity}")
        logger.info(f"Max iterations: {max_iterations}")
        
        # Execute the complete workflow
        try:
            final_state = workflow_engine.execute_workflow(initial_state, execution_id)
            execution_time = time.time() - start_time
            
            logger.info(f"Workflow completed successfully in {execution_time:.2f} seconds")
            
            # Record workflow metrics
            global_monitoring_system.record_workflow_execution(
                workflow_id=execution_id,
                node_name="complete_workflow",
                execution_time_ms=execution_time * 1000,
                success=True,
                memory_usage_mb=0,  # Would be calculated in real implementation
                error_count=0
            )
            
            # Extract results
            final_report = final_state.get("final_report", "No final report generated")
            quality_metrics = final_state.get("quality_metrics", {})
            iteration_count = final_state.get("iteration_count", 0)
            
            # Save report to file
            report_filename = f"report_{execution_id}.md"
            with open(report_filename, 'w', encoding='utf-8') as f:
                f.write(f"# Research Report: {topic}\n\n")
                f.write(f"**Generated by TTD-DR Framework**\n")
                f.write(f"**Execution ID:** {execution_id}\n")
                f.write(f"**Generated on:** {datetime.now().isoformat()}\n")
                f.write(f"**Execution Time:** {execution_time:.2f} seconds\n")
                f.write(f"**Iterations Completed:** {iteration_count}\n")
                f.write(f"**Quality Score:** {quality_metrics.get('overall_score', 'N/A')}\n\n")
                f.write("---\n\n")
                f.write(final_report)
                f.write("\n\n---\n")
                f.write(f"*Report generated by TTD-DR Framework v1.0*\n")
            
            logger.info(f"Report saved to: {report_filename}")
            
            # Print summary
            print(f"\n{'='*60}")
            print(f"RESEARCH REPORT COMPLETED: {topic}")
            print(f"{'='*60}")
            print(f"Execution ID: {execution_id}")
            print(f"Execution Time: {execution_time:.2f} seconds")
            print(f"Iterations: {iteration_count}")
            print(f"Quality Score: {quality_metrics.get('overall_score', 'N/A')}")
            print(f"Report Length: {len(final_report)} characters")
            print(f"Saved to: {report_filename}")
            print(f"{'='*60}\n")
            
            return {
                "success": True,
                "execution_id": execution_id,
                "execution_time": execution_time,
                "report_file": report_filename,
                "quality_score": quality_metrics.get('overall_score', 0),
                "iteration_count": iteration_count,
                "report_length": len(final_report)
            }
            
        except Exception as workflow_error:
            execution_time = time.time() - start_time
            logger.error(f"Workflow execution failed: {workflow_error}")
            
            # Record failed workflow metrics
            global_monitoring_system.record_workflow_execution(
                workflow_id=execution_id,
                node_name="complete_workflow",
                execution_time_ms=execution_time * 1000,
                success=False,
                memory_usage_mb=0,
                error_count=1
            )
            
            return {
                "success": False,
                "execution_id": execution_id,
                "execution_time": execution_time,
                "error": str(workflow_error)
            }
            
    except Exception as e:
        logger.error(f"Failed to run research report: {e}")
        import traceback
        traceback.print_exc()
        return {
            "success": False,
            "error": str(e)
        }

async def main():
    """Run two complete research reports"""
    print("üöÄ TTD-DR Framework Complete Demo")
    print("Generating two comprehensive research reports...")
    print("=" * 80)
    
    # Define two interesting research topics
    topics = [
        {
            "topic": "‰∫∫Â∑•Êô∫ËÉΩÂú®ÊïôËÇ≤È¢ÜÂüüÁöÑÂ∫îÁî®‰∏éÂèëÂ±ïË∂ãÂäø",
            "complexity": "intermediate",
            "max_iterations": 2,
            "description": "AI applications in education and future trends"
        },
        {
            "topic": "Âå∫ÂùóÈìæÊäÄÊúØÂú®‰æõÂ∫îÈìæÁÆ°ÁêÜ‰∏≠ÁöÑÂàõÊñ∞Â∫îÁî®",
            "complexity": "advanced", 
            "max_iterations": 3,
            "description": "Blockchain innovation in supply chain management"
        }
    ]
    
    results = []
    total_start_time = time.time()
    
    for i, topic_config in enumerate(topics, 1):
        print(f"\nüìä Report {i}/2: {topic_config['topic']}")
        print(f"Description: {topic_config['description']}")
        print(f"Complexity: {topic_config['complexity']}")
        print(f"Max Iterations: {topic_config['max_iterations']}")
        print("-" * 60)
        
        result = await run_complete_research_report(
            topic=topic_config["topic"],
            complexity=topic_config["complexity"],
            max_iterations=topic_config["max_iterations"]
        )
        
        results.append({
            "topic": topic_config["topic"],
            "description": topic_config["description"],
            "result": result
        })
        
        if result["success"]:
            print(f"‚úÖ Report {i} completed successfully!")
        else:
            print(f"‚ùå Report {i} failed: {result.get('error', 'Unknown error')}")
        
        # Brief pause between reports
        if i < len(topics):
            print("‚è≥ Preparing next report...")
            await asyncio.sleep(2)
    
    total_execution_time = time.time() - total_start_time
    
    # Final summary
    print("\n" + "=" * 80)
    print("üéâ TTD-DR FRAMEWORK DEMO COMPLETE")
    print("=" * 80)
    
    successful_reports = sum(1 for r in results if r["result"]["success"])
    failed_reports = len(results) - successful_reports
    
    print(f"Total Reports Generated: {len(results)}")
    print(f"Successful Reports: {successful_reports}")
    print(f"Failed Reports: {failed_reports}")
    print(f"Total Execution Time: {total_execution_time:.2f} seconds")
    
    print("\nReport Details:")
    print("-" * 40)
    
    for i, result_data in enumerate(results, 1):
        result = result_data["result"]
        print(f"\nReport {i}: {result_data['topic']}")
        print(f"Description: {result_data['description']}")
        
        if result["success"]:
            print(f"‚úÖ Status: SUCCESS")
            print(f"   Execution Time: {result['execution_time']:.2f}s")
            print(f"   Quality Score: {result['quality_score']}")
            print(f"   Iterations: {result['iteration_count']}")
            print(f"   Report Length: {result['report_length']} chars")
            print(f"   File: {result['report_file']}")
        else:
            print(f"‚ùå Status: FAILED")
            print(f"   Error: {result.get('error', 'Unknown error')}")
    
    # System monitoring summary
    try:
        from backend.services.monitoring_alerting import global_monitoring_system
        
        print("\n" + "=" * 40)
        print("SYSTEM MONITORING SUMMARY")
        print("=" * 40)
        
        health = global_monitoring_system.get_system_health()
        print(f"System Health: {health['overall_status']}")
        print(f"Active Alerts: {health['active_alerts']}")
        
        metrics = global_monitoring_system.get_performance_metrics(60)
        if metrics:
            print("Performance Metrics (last 60 minutes):")
            for metric_name, stats in metrics.items():
                if stats:
                    print(f"  {metric_name}: avg={stats.get('mean', 0):.2f}")
        
    except Exception as e:
        print(f"Could not retrieve monitoring summary: {e}")
    
    print("\nüéØ Demo completed! Check the generated report files for detailed results.")
    
    return results

if __name__ == "__main__":
    # Run the complete demo
    results = asyncio.run(main())
    
    # Exit with appropriate code
    successful = sum(1 for r in results if r["result"]["success"])
    exit(0 if successful > 0 else 1)